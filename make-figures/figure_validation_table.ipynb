{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\toprule\n",
      "dataset &  instances &  non-trivial &  avg nodes  &  avg deg & avg $k$  &  optimal &  non-optimal \\\\\n",
      "\\midrule\n",
      "\\zebra & 1549373 & 445880 & 18.49 & 2.27 & 2.32 &  99.907\\% & 0.053\\% \\\\ % 209\n",
      "\\mouse & 1316058 & 473185 & 18.67 & 2.37 & 2.75 &  99.401\\% & 0.074\\% \\\\ % 3075\n",
      "\\human & 1169083 & 529523 & 18.79 & 2.41 & 2.83 &  99.490\\% & 0.043\\% \\\\ % 3164\n",
      "\\salmon & 13300893 & 7153472 & 20.54 & 2.55 & 3.74 &  94.391\\% & 0.035\\% \\\\ % 398752\n",
      "\\midrule\n",
      "all & 17335407 & 8602060 & 20.22 & 2.52 & 3.55 & 95.266\\% & 0.039\\% \\\\ % 405200\n",
      "\n",
      "k_cut: 0.9653462077688367,  k_imp: 0.9842896933990231\n"
     ]
    }
   ],
   "source": [
    "# FILTER DATA\n",
    "from parse_truth_ALL import main as parse_truth_all\n",
    "import collections\n",
    "from algorithm_output_parser import process_algorithm_output\n",
    "from algorithm_output_parser import toboggan_output_parser\n",
    "from algorithm_output_parser import toboggan_clean_output_parser\n",
    "from algorithm_output_parser import catfish_output_parser\n",
    "\n",
    "# [1] COLLECT ALL GROUND TRUTH DATA\n",
    "from algorithm_output_parser import toboggan_output_parser\n",
    "\n",
    "\n",
    "froot_indices = [0,1,2,3]\n",
    "froots = ['zebra', 'mouse', 'human', 'salmon']\n",
    "datadirs = ['zebrafish', 'mouse', 'human', 'salmon']\n",
    "    \n",
    "print(\"\\\\toprule\")\n",
    "print(\"dataset &  instances &  non-trivial &  avg nodes  &  avg deg & avg $k$  &  optimal &  non-optimal \\\\\\\\\")\n",
    "print(\"\\\\midrule\")\n",
    "\n",
    "\n",
    "total_instances = 0\n",
    "total_nontrivials = 0\n",
    "total_optimals = 0\n",
    "total_nonoptimals = 0\n",
    "total_contracted_nodes = 0\n",
    "total_contracted_ave_deg = 0\n",
    "total_orig_nodes = 0\n",
    "total_orig_ave_deg = 0\n",
    "total_ave_kgtrue = 0\n",
    "\n",
    "total_timeouts = 0\n",
    "\n",
    "total_cutset_eq_opt = 0\n",
    "total_improv_eq_opt = 0\n",
    "\n",
    "\n",
    "for froot_idx in froot_indices:\n",
    "    froot = froots[froot_idx]\n",
    "    #print(\"working on {}...\".format(froot))\n",
    "    \n",
    "    num_instances = 0\n",
    "    num_nontrivial_instances = 0\n",
    "\n",
    "    num_gt_optimal_size = 0\n",
    "    num_gt_wrong_size = 0\n",
    "    num_timeouts = 0\n",
    "\n",
    "    ave_k_gtrue = 0\n",
    "    ave_num_nodes_contracted = 0\n",
    "    ave_deg_contracted = 0\n",
    "    ave_num_nodes_orig = 0\n",
    "    ave_deg_orig = 0\n",
    "\n",
    "    this_cutset_eq_opt = 0\n",
    "    this_improv_eq_opt = 0\n",
    "\n",
    "    # COUNT RELEVANT INFO\n",
    "\n",
    "    datadirending = datadirs[froot_idx]\n",
    "    datadir = '/home/kyle/data/rnaseq/' + datadirending + '/'\n",
    "\n",
    "    # [0] Get data from toboggan\n",
    "    inputfile = \"./data/all-\" + froot + \".txt\"\n",
    "    \n",
    "    truth_dict = {}\n",
    "    with open('./data/truth-size-' + froot + '.txt', 'r') as infile:\n",
    "        for line in infile:\n",
    "            parts = line.strip().split()\n",
    "            key = parts[0] + ' ' + parts[1]\n",
    "            truth_dict[key] = int(parts[2])\n",
    "    \n",
    "    temp_dict = collections.defaultdict(int)\n",
    "    \n",
    "    with open(inputfile,'r') as infile:\n",
    "        for line in infile:\n",
    "            \n",
    "            temp_parts = line.strip().split()\n",
    "            temp_key = temp_parts[0].split('.')[0] + ' ' + temp_parts[1]\n",
    "\n",
    "            if temp_dict[temp_key] == 0:\n",
    "                num_instances += 1\n",
    "                n_orig = int(temp_parts[2])\n",
    "                m_orig = int(temp_parts[3])\n",
    "                n_red = int(temp_parts[4])\n",
    "                m_red = int(temp_parts[5])\n",
    "                # k_gtrue = int(temp_parts[6])\n",
    "                k_gtrue = truth_dict[temp_key]\n",
    "\n",
    "                if k_gtrue > 1:\n",
    "                    num_nontrivial_instances += 1\n",
    "                    ave_k_gtrue += k_gtrue\n",
    "                    \n",
    "                else:  # skip trivial instances\n",
    "                    continue\n",
    "\n",
    "\n",
    "                k_cutset = int(temp_parts[7])\n",
    "                k_improv = int(temp_parts[8])\n",
    "                \n",
    "                if k_cutset == k_gtrue:\n",
    "                    this_cutset_eq_opt += 1\n",
    "                if k_improv == k_gtrue:\n",
    "                    this_improv_eq_opt += 1\n",
    "\n",
    "                k_opt = temp_parts[9]\n",
    "                if k_opt != 'None':\n",
    "                    k_opt = int(k_opt)\n",
    "                    if k_opt == k_gtrue:\n",
    "                        num_gt_optimal_size += 1\n",
    "                    elif k_opt < k_gtrue:\n",
    "                        num_gt_wrong_size += 1\n",
    "                else:\n",
    "                    num_timeouts +=1\n",
    "\n",
    "                ave_num_nodes_contracted += n_red\n",
    "                ave_deg_contracted += 2*(m_red/n_red)\n",
    "                ave_num_nodes_orig += n_orig\n",
    "                ave_deg_orig += 2*(m_orig/n_orig)\n",
    "                \n",
    "                temp_dict[temp_key] = k_opt\n",
    "            else:\n",
    "                k_gtrue = truth_dict[temp_key]\n",
    "                k_opt = temp_parts[9]\n",
    "                if k_opt != temp_dict[temp_key]:\n",
    "                    if k_opt != 'None':\n",
    "                        k_opt = int(k_opt)\n",
    "                        if k_opt == k_gtrue:\n",
    "                            num_gt_optimal_size += 1\n",
    "                        elif k_opt < k_gtrue:\n",
    "                            num_gt_wrong_size += 1\n",
    "                \n",
    "            \n",
    "            \"\"\"\n",
    "            row = [ filename, instancenum, n, m, n_red, m_red,\n",
    "                           k_groundtruth, cutset_bound, improved_bound, k_opt,\n",
    "                           t_w, t_path, timeout_flag, timeout_limit, graphname]\n",
    "            \"\"\"\n",
    "    \n",
    "    total_ave_kgtrue += ave_k_gtrue\n",
    "    total_contracted_nodes += ave_num_nodes_contracted\n",
    "    total_contracted_ave_deg += ave_deg_contracted\n",
    "    total_orig_nodes += ave_num_nodes_orig\n",
    "    total_orig_ave_deg += ave_deg_orig\n",
    "    \n",
    "    total_cutset_eq_opt += this_cutset_eq_opt\n",
    "    total_improv_eq_opt += this_improv_eq_opt\n",
    "\n",
    "    ave_k_gtrue = ave_k_gtrue / num_nontrivial_instances\n",
    "    ave_num_nodes_contracted = ave_num_nodes_contracted / num_nontrivial_instances\n",
    "    ave_deg_contracted = ave_deg_contracted / num_nontrivial_instances\n",
    "    ave_num_nodes_orig = ave_num_nodes_orig / num_nontrivial_instances\n",
    "    ave_deg_orig = ave_deg_orig / num_nontrivial_instances\n",
    "    \n",
    "    total_instances += num_instances\n",
    "    total_nontrivials += num_nontrivial_instances\n",
    "    total_optimals += num_gt_optimal_size\n",
    "    total_nonoptimals += num_gt_wrong_size\n",
    "    total_timeouts += num_timeouts\n",
    "        \n",
    "    print(\"\\\\{} & {:d} & {:d} & {:3.2f} & {:3.2f} & {:3.2f} &  {:3.3f}\\\\% & {:3.3f}\\\\% \\\\\\\\ % {}\".format(froot,\n",
    "        num_instances, num_nontrivial_instances, ave_num_nodes_orig, ave_deg_orig, ave_k_gtrue,\n",
    "        100*num_gt_optimal_size/(num_nontrivial_instances), 100*num_gt_wrong_size/num_nontrivial_instances,\n",
    "        num_timeouts, len(truth_dict)))\n",
    "\n",
    "print(\"\\\\midrule\")\n",
    "print(\"{} & {:d} & {:d} & {:3.2f} & {:3.2f} & {:3.2f} & {:3.3f}\\\\% & {:3.3f}\\\\% \\\\\\\\ % {}\".format('all',\n",
    "        total_instances, total_nontrivials, total_orig_nodes/total_nontrivials,\n",
    "        total_orig_ave_deg/total_nontrivials , total_ave_kgtrue/total_nontrivials,\n",
    "        100*total_optimals/(total_nontrivials), 100*total_nonoptimals/total_nontrivials, total_timeouts))\n",
    "\n",
    "print(\"\")\n",
    "print(\"k_cut: {},  k_imp: {}\".format(total_cutset_eq_opt/total_nontrivials, total_improv_eq_opt/total_nontrivials) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5037866719829537"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(17335407 - 8602060) / 17335407"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
